{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Desmprimir el archivo zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"./trec07p.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"datasets/\")"
      ],
      "metadata": {
        "id": "vITIbfmAMIgF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0ezJYRQaK8gq"
      },
      "outputs": [],
      "source": [
        "# Esta clase facilita el preprocesamiento de correos electrónicos que poseen código HTML\n",
        "from html.parser import HTMLParser\n",
        "\n",
        "class MLStripper(HTMLParser):\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "    self.strict = False\n",
        "    self.convert_charrefs = True\n",
        "    self.fed = []\n",
        "  def handle_data(self, d):\n",
        "    self.fed.append(d)\n",
        "  def get_data(self):\n",
        "    return ''.join(self.fed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_tags(html):\n",
        "  s = MLStripper()\n",
        "  s.feed(html)\n",
        "  return s.get_data()"
      ],
      "metadata": {
        "id": "i8tJsFr5LMz-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de eliminación de los tags HTML de un texto\n",
        "t = '<tr><td align=\"left\"><a href=\"../../issues/51/16.html#article\">Phrack World News</a></td>'\n",
        "strip_tags(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KhzNx-SNLTiB",
        "outputId": "324a59fa-9cc9-44a7-b4cf-007594e63432"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Phrack World News'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import email\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "class Parser:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.stemmer = nltk.PorterStemmer()\n",
        "    self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    self.punctuation = list(string.punctuation)\n",
        "\n",
        "  def parse(self, email_path):\n",
        "    \"\"\"Parse an email.\"\"\"\n",
        "    with open(email_path, errors='ignore') as e:\n",
        "      msg = email.message_from_file(e)\n",
        "    return None if not msg else self.get_email_content(msg)\n",
        "\n",
        "  def get_email_content(self, msg):\n",
        "    \"\"\"Extract the email content.\"\"\"\n",
        "    subject = self.tokenize(msg['Subject']) if msg['Subject'] else []\n",
        "    body = self.get_email_body(msg.get_payload(),\n",
        "                  msg.get_content_type())\n",
        "    content_type = msg.get_content_type()\n",
        "    # Returning the content of the email\n",
        "    return {\"subject\": subject,\n",
        "        \"body\": body,\n",
        "        \"content_type\": content_type}\n",
        "\n",
        "  def get_email_body(self, payload, content_type):\n",
        "    \"\"\"Extract the body of the email.\"\"\"\n",
        "    body = []\n",
        "    if type(payload) is str and content_type == 'text/plain':\n",
        "      return self.tokenize(payload)\n",
        "    elif type(payload) is str and content_type == 'text/html':\n",
        "      return self.tokenize(strip_tags(payload))\n",
        "    elif type(payload) is list:\n",
        "      for p in payload:\n",
        "        body += self.get_email_body(p.get_payload(),\n",
        "                      p.get_content_type())\n",
        "    return body\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Transform a text string in tokens. Perform two main actions,\n",
        "    clean the punctuation symbols and do stemming of the text.\"\"\"\n",
        "    for c in self.punctuation:\n",
        "      text = text.replace(c, \"\")\n",
        "    text = text.replace(\"\\t\", \" \")\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    tokens = list(filter(None, text.split(\" \")))\n",
        "    # Stemming of the tokens\n",
        "    return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]\n",
        "\n",
        "#Lectura de un correo en formato raw\n",
        "inmail = open(\"datasets/trec07p/data/inmail.1\").read()\n",
        "print(inmail)\n",
        "\n",
        "#Parsing del correo electrónico\n",
        "p = Parser()\n",
        "p.parse(\"datasets/trec07p/data/inmail.1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsuAZhIILbOq",
        "outputId": "b3180fda-c5e2-4756-9738-232affaad2cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From RickyAmes@aol.com  Sun Apr  8 13:07:32 2007\n",
            "Return-Path: <RickyAmes@aol.com>\n",
            "Received: from 129.97.78.23 ([211.202.101.74])\n",
            "\tby speedy.uwaterloo.ca (8.12.8/8.12.5) with SMTP id l38H7G0I003017;\n",
            "\tSun, 8 Apr 2007 13:07:21 -0400\n",
            "Received: from 0.144.152.6 by 211.202.101.74; Sun, 08 Apr 2007 19:04:48 +0100\n",
            "Message-ID: <WYADCKPDFWWTWTXNFVUE@yahoo.com>\n",
            "From: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
            "Reply-To: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
            "To: the00@speedy.uwaterloo.ca\n",
            "Subject: Generic Cialis, branded quality@ \n",
            "Date: Sun, 08 Apr 2007 21:00:48 +0300\n",
            "X-Mailer: Microsoft Outlook Express 6.00.2600.0000\n",
            "MIME-Version: 1.0\n",
            "Content-Type: multipart/alternative;\n",
            "\tboundary=\"--8896484051606557286\"\n",
            "X-Priority: 3\n",
            "X-MSMail-Priority: Normal\n",
            "Status: RO\n",
            "Content-Length: 988\n",
            "Lines: 24\n",
            "\n",
            "----8896484051606557286\n",
            "Content-Type: text/html;\n",
            "Content-Transfer-Encoding: 7Bit\n",
            "\n",
            "<html>\n",
            "<body bgcolor=\"#ffffff\">\n",
            "<div style=\"border-color: #00FFFF; border-right-width: 0px; border-bottom-width: 0px; margin-bottom: 0px;\" align=\"center\">\n",
            "<table style=\"border: 1px; border-style: solid; border-color:#000000;\" cellpadding=\"5\" cellspacing=\"0\" bgcolor=\"#CCFFAA\">\n",
            "<tr>\n",
            "<td style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
            "<center>\n",
            "Do you feel the pressure to perform and not rising to the occasion??<br>\n",
            "</center>\n",
            "</td></tr><tr>\n",
            "<td bgcolor=#FFFF33 style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
            "<center>\n",
            "\n",
            "<b><a href='http://excoriationtuh.com/?lzmfnrdkleks'>Try <span>V</span><span>ia<span></span>gr<span>a</span>.....</a></b></center>\n",
            "</td></tr><td><center>your anxiety will be a thing of the past and you will<br>\n",
            "be back to your old self.\n",
            "</center></td></tr></table></div></body></html>\n",
            "\n",
            "\n",
            "----8896484051606557286--\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'subject': ['gener', 'ciali', 'brand', 'qualiti'],\n",
              " 'body': ['do',\n",
              "  'feel',\n",
              "  'pressur',\n",
              "  'perform',\n",
              "  'rise',\n",
              "  'occas',\n",
              "  'tri',\n",
              "  'viagra',\n",
              "  'anxieti',\n",
              "  'thing',\n",
              "  'past',\n",
              "  'back',\n",
              "  'old',\n",
              "  'self'],\n",
              " 'content_type': 'multipart/alternative'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estas funciones complementarias se encargan cargar en memoria la ruta de cada correo electrónico y su etiqueta correspondiente {spam, ham}\n",
        "index = open(\"datasets/trec07p/full/index\").readlines()\n",
        "\n",
        "import os\n",
        "DATASET_PATH = \"trec07p\"\n",
        "def parse_index(path_to_index, n_elements):\n",
        "  ret_indexes = []\n",
        "  index = open(path_to_index).readlines()\n",
        "  for i in range(n_elements):\n",
        "    mail = index[i].split(\" ../\")\n",
        "    label = mail[0]\n",
        "    path = mail[1][:-1]\n",
        "    ret_indexes.append({\"label\":label, \"email_path\":os.path.join(DATASET_PATH, path)})\n",
        "  return ret_indexes\n",
        "\n",
        "def parse_email(index):\n",
        "  p = Parser()\n",
        "  pmail = p.parse(index[\"email_path\"])\n",
        "  return pmail, index[\"label\"]\n",
        "indexes = parse_index(\"datasets/trec07p/full/index\", 10)"
      ],
      "metadata": {
        "id": "ZyFQ3bWCLbyN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el índice y las etiquetas en memoria\n",
        "index = parse_index(\"datasets/trec07p/full/index\", 1)\n",
        "# Leemos el primer correo\n",
        "import os\n",
        "open(index[0][\"email_path\"]).read()\n",
        "# Parseamos el primer correo\n",
        "mail, label = parse_email(index[0])\n",
        "print(\"El correo es:\", label)\n",
        "print(mail)\n",
        "#El algoritmo de Regresión Logística no es capaz de ingerir texto como parte del conjunto de datos.\n",
        "#Por lo tanto, deben aplicarse una serie de funciones adicionales que transformen el texto de los correos electrónicos parseados en una representación numérica.\n",
        "#Aplicación de CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Preapración del email en una cadena de texto\n",
        "prep_email = [\" \".join(mail['subject']) + \" \".join(mail['body'])]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit(prep_email)\n",
        "print(\"Email:\", prep_email, \"\\n\")\n",
        "try:\n",
        "    feature_names = vectorizer.get_feature_names_out()  # New sklearn versions\n",
        "except AttributeError:\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "print(\"Características de entrada:\", feature_names)\n",
        "X = vectorizer.transform(prep_email)\n",
        "print(\"\\nValues:\\n\", X.toarray())\n",
        "# Aplicación de OneHotEncoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "prep_email = [[w] for w in mail['subject'] + mail['body']]\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "X = enc.fit_transform(prep_email)\n",
        "print(\"Features:\\n\", feature_names)\n",
        "print(\"\\nValues:\\n\", X.toarray())\n",
        "# Funciones auxiliares para preprocesamiento del conjunto de datos\n",
        "def create_prep_dataset(index_path, n_elements):\n",
        "  X = []\n",
        "  y = []\n",
        "  indexes = parse_index(index_path, n_elements)\n",
        "  for i in range(n_elements):\n",
        "    print(\"\\rParsing email: {0}\".format(i+1), end='')\n",
        "    mail, label = parse_email(indexes[i])\n",
        "    X.append(\" \".join(mail['subject']) + \" \".join(mail['body']))\n",
        "    y.append(label)\n",
        "  return X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnWkiuMHLeAR",
        "outputId": "a888c66d-a85e-4235-d8be-294bd12c529e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El correo es: spam\n",
            "{'subject': ['gener', 'ciali', 'brand', 'qualiti'], 'body': ['do', 'feel', 'pressur', 'perform', 'rise', 'occas', 'tri', 'viagra', 'anxieti', 'thing', 'past', 'back', 'old', 'self'], 'content_type': 'multipart/alternative'}\n",
            "Email: ['gener ciali brand qualitido feel pressur perform rise occas tri viagra anxieti thing past back old self'] \n",
            "\n",
            "Características de entrada: ['anxieti' 'back' 'brand' 'ciali' 'feel' 'gener' 'occas' 'old' 'past'\n",
            " 'perform' 'pressur' 'qualitido' 'rise' 'self' 'thing' 'tri' 'viagra']\n",
            "\n",
            "Values:\n",
            " [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
            "Features:\n",
            " ['anxieti' 'back' 'brand' 'ciali' 'feel' 'gener' 'occas' 'old' 'past'\n",
            " 'perform' 'pressur' 'qualitido' 'rise' 'self' 'thing' 'tri' 'viagra']\n",
            "\n",
            "Values:\n",
            " [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos únicamente un subconjunto de 100 correos electrónicos\n",
        "X_train, y_train = create_prep_dataset(\"datasets/trec07p/full/index\", 100)\n",
        "\n",
        "# Aplicamos la sectorización a los datos\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "try:\n",
        "    feature_names = vectorizer.get_feature_names_out()  # New sklearn versions\n",
        "except AttributeError:\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "print(X_train.toarray())\n",
        "print(\"\\nFeatures:\", len(feature_names))\n",
        "import pandas as pd\n",
        "pd.DataFrame(X_train.toarray(), columns=[feature_names])\n",
        "# Entrenamiento del algoritmo de regresión logística con el conjunto de datos preprocesado (ver en sklearn logistic)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# TODO ejecuta .fit() con los parámetros de entrada X_train e y_train\n",
        "logisticRegression = LogisticRegression()\n",
        "logisticRegression.fit(X_train, y_train)\n",
        "#4.- Predicción\n",
        "#Lectura de un conjunto de correos nuevos:\n",
        "# Leemos 150 correos de nuestro conjunto de datos y nos quedamos únicamente con los 50 últimos\n",
        "# Estos 50 correos electrónicos no se han utilizado para entrenar el algoritmo\n",
        "X, y = create_prep_dataset(\"datasets/trec07p/full/index\", 150)\n",
        "X_test = X[100:]\n",
        "y_test = y[100:]\n",
        "\n",
        "#TODO Preprocesalos con el vectorizador creado anteriormente\n",
        "X_test = vectorizer.transform(X_test)\n",
        "#TODO Predice el tipo de correo para estos correos de test\n",
        "y_pred = logisticRegression.predict(X_test)\n",
        "#Evalúa los resultados\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMQdhXMCLgxS",
        "outputId": "98db11a6-a3e9-4e8e-8b32-cd3264f79d7e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing email: 100[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Features: 4911\n",
            "Parsing email: 150Accuracy: 0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Repite el proceso leyendo 12k correos electrónicos, de los cuales utiliza 10k para entrenar el algoritmo y 2k para probarlo.\n",
        "X, Y = create_prep_dataset(\"datasets/trec07p/full/index\", 12000)\n",
        "\n",
        "x_train, x_test = X[:10000], X[10000:]\n",
        "y_train, y_test = Y[:10000], Y[10000:]\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "x_train = vectorizer.fit_transform(x_train)\n",
        "\n",
        "try:\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "except AttributeError:\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "print(x_train.toarray())\n",
        "print(\"\\nFeatures:\", len(feature_names))\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(x_train.toarray(), columns=feature_names)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegression = LogisticRegression()\n",
        "logisticRegression.fit(x_train, y_train)\n",
        "\n",
        "x_test = vectorizer.transform(x_test)\n",
        "y_pred = logisticRegression.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l2PzoUNLizJ",
        "outputId": "0080a2dd-9983-4506-d488-1c8fd9e7b892"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing email: 12000[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Features: 5000\n",
            "Accuracy: 0.988\n"
          ]
        }
      ]
    }
  ]
}